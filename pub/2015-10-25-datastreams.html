<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">

  <base href="/pub/">

  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Open+Sans:300,400,600,700&amp;lang=en" />

  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro&display=swap" rel="stylesheet">

  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro&display=swap" rel="stylesheet">

  <link href="https://fonts.googleapis.com/css?family=Patua+One&display=swap" rel="stylesheet">

  <meta name="viewport" content="width=device-width, initial-scale=1">

   <!-- Un-minified script so that can play a bit -->
<link rel="stylesheet" href="/libs/katex/katex.min.css">
     
  

  <link rel="stylesheet" href="/css/judoc.css">
  <link rel="stylesheet" href="/css/basic.css">
  <link rel="stylesheet" href="/css/julialangblog.css">
  <link rel="icon"       href="/assets/infra/favicon.png">

   <title>JSoC 2015 project: DataStreams.jl</title>  
</head>

<body>
  <header>
    <div class="blog-name">The <a href="https://julialang.org/blog/">Julia language blog</a> (mirror)</div>
    <nav>
      <ul>
        <li><a href="/">Home</a></li>
      </ul>
      <img src="/assets/infra/hamburger.svg" id="menu-icon">
    </nav>
  </header>

  <div class="jd-content">
    
    <h1>JSoC 2015 project: DataStreams.jl</h1>
    

    <h3>
       <span style="font-weight: lighter;"> 25 October 2015 </span>
      |
      
       <span style="font-weight: bold;"> <a href="https://github.com/quinnj">Jacob Quinn</a> </span> 
  </h3>

  </div>

<!-- Content appended here -->

<div class="jd-content">
<p>Data processing got ya down? Good news&#33; The <a href="https://github.com/JuliaDB/DataStreams.jl">DataStreams.jl</a> package, er, framework, has arrived&#33;</p>
<p>The DataStreams processing framework provides a consistent interface for working with data, from source to sink and eventually every step in-between. It&#39;s really about putting forth an interface &#40;specific types and methods&#41; to go about ingesting and transferring data sources that hopefully makes for a consistent experience for users, no matter what kind of data they&#39;re working with.</p>
<h3><a id="how_does_it_work" href="#how_does_it_work">How does it work?</a></h3> DataStreams is all about creating &quot;sources&quot; &#40;Julia types that represent true data sources; e.g. csv files, database backends, etc.&#41;, &quot;sinks&quot; or data destinations, and defining the appropriate <code>Data.stream&#33;&#40;source, sink&#41;</code> methods to actually transfer data from source to sink. Let&#39;s look at a quick example.</p>
<p>Say I have a table of data in a CSV file on my local machine and need to do a little cleaning and aggregation on the data before building a model with the <a href="https://github.com/JuliaStats/GLM.jl">GLM.jl</a> package. Let&#39;s see some code in action:</p>
<pre><code class="language-julia">
using CSV, SQLite, DataStreams, DataFrames

# let&#39;s create a Julia type that understands our data file
csv_source &#61; CSV.Source&#40;&quot;datafile.csv&quot;&#41;

# let&#39;s also create an SQLite destination for our data
# according to its structure
db &#61; SQLite.DB&#40;&#41; # create an in-memory SQLite database

# creates an SQLite table
sqlite_sink &#61; SQLite.Sink&#40;Data.schema&#40;csv_source&#41;, db, &quot;mydata&quot;&#41;

# parse the CSV data directly into our SQLite table
Data.stream&#33;&#40;csv_source, sqlite_sink&#41;

# now I can do some data cleansing/aggregation
# ...various SQL statements on the &quot;mydata&quot; SQLite table...

# now I&#39;m ready to get my data out and ready for model fitting
sqlite_source &#61; SQLite.Source&#40;sqlite_sink&#41;

# stream our data into a Julia structure &#40;Data.Table&#41;
dt &#61; Data.stream&#33;&#40;sqlite_source, Data.Table&#41;

# convert to DataFrame &#40;non-copying&#41;
df &#61; DataFrame&#40;dt&#41;

# do model-fitting
OLS &#61; glm&#40;Y~X,df,Normal&#40;&#41;,IdentityLink&#40;&#41;&#41;
</code></pre>
<p>Here we see it&#39;s quite simple to create a <code>Source</code> type by wrapping a true datasource &#40;our CSV file&#41;, a destination for that data &#40;an SQLite table&#41;, and to transfer the data. We can then turn our <code>SQLite.Sink</code> into an <code>SQLite.Source</code> for getting the data back out again.</p>
<h3><a id="so_what_have_you_really_been_working_on" href="#so_what_have_you_really_been_working_on">So What Have You Really Been Working On?</a></h3> Well, a lot actually. Even though the DataStreams framework is currently simple and minimalistic, it took a lot of back and forth on the design, including several discussions at this year&#39;s JuliaCon at MIT. Even with a tidy little framework, however, the bulk of the work still lies in actually implementing the interface in various packages. The two that are ready for release today are <a href="https://github.com/JuliaDB/CSV.jl">CSV.jl</a> and <a href="https://github.com/JuliaDB/SQLite.jl">SQLite.jl</a>. They are currently available for julia 0.4&#43; only.</p>
<p>Quick rundown of each package:</p>
<ul>
<li><p>CSV: provides types and methods for working with CSV and other delimited files. Aims to be &#40;and currently is&#41; the fastest and most flexible CSV reader in Julia.</p>
</li>
<li><p>SQLite: an interface to the popular <a href="http://sqlite.org/">SQLite</a> local-machine database. Provides methods for creating/managing database files, along with executing SQL statements and viewing the results of such.</p>
</li>
</ul>
<h3><a id="so_whats_next" href="#so_whats_next">So What&#39;s Next?</a></h3> <a href="https://github.com/JuliaDB/ODBC.jl">ODBC.jl</a>: the next package to get the DataStreams makeover is ODBC. I&#39;ve already started work on this and hopefully should be ready soon.</p>
<ul>
<li><p>Other packages: I&#39;m always on the hunt for new ways to spread the framework; if you&#39;d be interested in implementing DataStreams for your own package or want to collaborate, just <a href="https://github.com/quinnj">ping</a> me and I&#39;m happy to discuss&#33;</p>
</li>
<li><p>transforms: an important part of data processing tasks is not just connecting to and moving the data to somewhere else: often you need to clean/transform/aggregate the data in some way in-between. Right now, that&#39;s up to users, but I have some ideas around creating DataStreams-friendly ways to easily incorporate transform steps as data is streamed from one place to another.</p>
</li>
<li><p>DataStreams for chaining pipelines &#43; transforms: I&#39;m also excited about the idea of creating entire <code>DataStreams</code>, which would define entire data processing tasks end-to-end. Setting up a pipeline that could consistently move and process data gets even more powerful as we start looking into automatic-parallelism and extensibility.</p>
</li>
<li><p>DataStream scheduling/management: I&#39;m also interested in developing capabilities around scheduling and managing DataStreams.</p>
</li>
</ul>
<p><em>The work on DataStreams.jl was carried out as part of the Julia Summer of Code program, made possible thanks to the generous support of the <a href="https://moore.org">Gordon and Betty Moore Foundation</a>, and MIT.</em></p>

<div class="page-foot">
  <div class="copyright">
    &copy; Last modified: September 14, 2019. Website built with <a href="https://github.com/tlienart/JuDoc.jl">JuDoc.jl</a>.
  </div>
</div>

</div>
<!-- CONTENT ENDS HERE -->
    
        <script src="/libs/katex/katex.min.js"></script>
<script src="/libs/katex/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
  </body>
</html>
